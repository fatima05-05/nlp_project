{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP3Y6Zr6NTbXObXysx7QELn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["A https://huggingface.co/datasets/Deysi/spam-detection-dataset dataset beimport√°l√°sa a hugging face oldal√°r√≥l."],"metadata":{"id":"14lkLpfZ4Dsi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNq2JUiH3zGy"},"outputs":[],"source":["import pandas as pd\n","\n","splits = {'train': 'data/train-00000-of-00001-daf190ce720b3dbb.parquet', 'test': 'data/test-00000-of-00001-fa9b3e8ade89a333.parquet'}\n","df = pd.read_parquet(\"hf://datasets/Deysi/spam-detection-dataset/\" + splits[\"train\"])\n","\n","df.head()"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(8, 6))\n","sns.countplot(x='label', data=df)\n","plt.title('Distribution of Labels in the Dataset')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.show()"],"metadata":{"id":"QEkBg-mfD2Hj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A dataset kisbet≈±ss√© alak√≠t√°sa"],"metadata":{"id":"ouVVgGTU4krG"}},{"cell_type":"code","source":["def to_lowercase(text):\n","  \"\"\"Converts text to lowercase.\"\"\"\n","  return text.lower()"],"metadata":{"id":"TPrMUEG45Ff2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","\n","class TestToLowercase(unittest.TestCase):\n","\n","  def test_to_lowercase(self):\n","    self.assertEqual(to_lowercase(\"HELLO WORLD\"), \"hello world\")\n","    self.assertEqual(to_lowercase(\"This is a Test\"), \"this is a test\")\n","    self.assertEqual(to_lowercase(\"Another EXAMPLE 123\"), \"another example 123\")\n","    self.assertEqual(to_lowercase(\"MIXED cAsE\"), \"mixed case\")\n","    self.assertEqual(to_lowercase(\"already lowercase\"), \"already lowercase\")\n","\n","unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"id":"lqYnrgoW5NSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'] = df['text'].apply(to_lowercase)\n","display(df.head())"],"metadata":{"id":"CQqKVugC4Atd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["whitespacek elt√°vol√≠t√°sa"],"metadata":{"id":"iVMY3ng74-FZ"}},{"cell_type":"code","source":["import re\n","\n","def remove_whitespace(text):\n","  \"\"\"Removes extra whitespaces from text.\"\"\"\n","  return re.sub(r'\\s+', ' ', text).strip()"],"metadata":{"id":"rjD2xkEi5DFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","\n","class TestRemoveWhitespace(unittest.TestCase):\n","\n","  def test_remove_whitespace(self):\n","    self.assertEqual(remove_whitespace(\"Hello   World\"), \"Hello World\")\n","    self.assertEqual(remove_whitespace(\"  Leading and trailing spaces  \"), \"Leading and trailing spaces\")\n","    self.assertEqual(remove_whitespace(\"Multiple\\nlines\\nwith\\t tabs\"), \"Multiple lines with tabs\")\n","    self.assertEqual(remove_whitespace(\"SingleSpace\"), \"SingleSpace\")\n","    self.assertEqual(remove_whitespace(\"\"), \"\")\n","\n","unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"id":"bVyWZO-g5mnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'] = df['text'].apply(remove_whitespace)\n","display(df.head())"],"metadata":{"id":"4GZPghf35wjQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Kontrakci√≥k kibont√°sa"],"metadata":{"id":"Bb6IA1Tu7OeA"}},{"cell_type":"code","source":["def expand_contractions(text):\n","    \"\"\"Expands contractions in text.\"\"\"\n","    contractions_dict = {\n","        \"ain't\": \"am not\",\n","        \"aren't\": \"are not\",\n","        \"can't\": \"cannot\",\n","        \"can't've\": \"cannot have\",\n","        \"'cause\": \"because\",\n","        \"could've\": \"could have\",\n","        \"couldn't\": \"could not\",\n","        \"couldn't've\": \"could not have\",\n","        \"didn't\": \"did not\",\n","        \"doesn't\": \"does not\",\n","        \"don't\": \"do not\",\n","        \"hadn't\": \"had not\",\n","        \"hadn't've\": \"had not have\",\n","        \"hasn't\": \"has not\",\n","        \"haven't\": \"have not\",\n","        \"he'd\": \"he would\",\n","        \"he'd've\": \"he would have\",\n","        \"he'll\": \"he will\",\n","        \"he'll've\": \"he will have\",\n","        \"he's\": \"he is\",\n","        \"how'd\": \"how did\",\n","        \"how'd'y\": \"how do you\",\n","        \"how'll\": \"how will\",\n","        \"how's\": \"how is\",\n","        \"i'd\": \"i would\",\n","        \"i'd've\": \"i would have\",\n","        \"i'll\": \"i will\",\n","        \"i'll've\": \"i will have\",\n","        \"i'm\": \"i am\",\n","        \"i've\": \"i have\",\n","        \"isn't\": \"is not\",\n","        \"it'd\": \"it would\",\n","        \"it'd've\": \"it would have\",\n","        \"it'll\": \"it will\",\n","        \"it'll've\": \"it will have\",\n","        \"it's\": \"it is\",\n","        \"let's\": \"let us\",\n","        \"ma'am\": \"madam\",\n","        \"mayn't\": \"may not\",\n","        \"might've\": \"might have\",\n","        \"mightn't\": \"might not\",\n","        \"mightn't've\": \"might not have\",\n","        \"must've\": \"must have\",\n","        \"mustn't\": \"must not\",\n","        \"mustn't've\": \"must not have\",\n","        \"needn't\": \"need not\",\n","        \"needn't've\": \"need not have\",\n","        \"o'clock\": \"of the clock\",\n","        \"oughtn't\": \"ought not\",\n","        \"oughtn't've\": \"ought not have\",\n","        \"shan't\": \"shall not\",\n","        \"sha'n't\": \"shall not\",\n","        \"shan't've\": \"shall not have\",\n","        \"she'd\": \"she would\",\n","        \"she'd've\": \"she would have\",\n","        \"she'll\": \"she will\",\n","        \"she'll've\": \"she will have\",\n","        \"she's\": \"she is\",\n","        \"should've\": \"should have\",\n","        \"shouldn't\": \"should not\",\n","        \"shouldn't've\": \"should not have\",\n","        \"so's\": \"so is\",\n","        \"so've\": \"so have\",\n","        \"that'd\": \"that would\",\n","        \"that'd've\": \"that would have\",\n","        \"that's\": \"that is\",\n","        \"there'd\": \"there would\",\n","        \"there'd've\": \"there would have\",\n","        \"there's\": \"there is\",\n","        \"they'd\": \"they would\",\n","        \"they'd've\": \"they would have\",\n","        \"they'll\": \"they will\",\n","        \"they'll've\": \"they will have\",\n","        \"they're\": \"they are\",\n","        \"they've\": \"they have\",\n","        \"to've\": \"to have\",\n","        \"wasn't\": \"was not\",\n","        \"we'd\": \"we would\",\n","        \"we'd've\": \"we would have\",\n","        \"we'll\": \"we will\",\n","        \"we'll've\": \"we will have\",\n","        \"we're\": \"we are\",\n","        \"we've\": \"we have\",\n","        \"weren't\": \"were not\",\n","        \"what'll\": \"what will\",\n","        \"what'll've\": \"what will have\",\n","        \"what're\": \"what are\",\n","        \"what's\": \"what is\",\n","        \"what've\": \"what have\",\n","        \"when's\": \"when is\",\n","        \"when've\": \"when have\",\n","        \"where'd\": \"where did\",\n","        \"where's\": \"where is\",\n","        \"where've\": \"where have\",\n","        \"who'll\": \"who will\",\n","        \"who'll've\": \"who will have\",\n","        \"who's\": \"who is\",\n","        \"who've\": \"who have\",\n","        \"why's\": \"why is\",\n","        \"why've\": \"why have\",\n","        \"will've\": \"will have\",\n","        \"won't\": \"will not\",\n","        \"won't've\": \"will not have\",\n","        \"would've\": \"would have\",\n","        \"wouldn't\": \"would not\",\n","        \"wouldn't've\": \"would not have\",\n","        \"y'all\": \"you all\",\n","        \"y'all'd\": \"you all would\",\n","        \"y'all'd've\": \"you all would have\",\n","        \"y'all're\": \"you all are\",\n","        \"y'all've\": \"you all have\",\n","        \"you'd\": \"you would\",\n","        \"you'd've\": \"you would have\",\n","        \"you'll\": \"you will\",\n","        \"you'll've\": \"you will have\",\n","        \"you're\": \"you are\",\n","        \"you've\": \"you have\"\n","    }\n","\n","    contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n","\n","    def replace(match):\n","        return contractions_dict[match.group(0)]\n","\n","    return contractions_re.sub(replace, text)"],"metadata":{"id":"azvF5Hda7RDm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","\n","class TestExpandContractions(unittest.TestCase):\n","\n","  def test_expand_contractions(self):\n","    self.assertEqual(expand_contractions(\"i'm happy\"), \"i am happy\")\n","    self.assertEqual(expand_contractions(\"she's a doctor\"), \"she is a doctor\")\n","    self.assertEqual(expand_contractions(\"they don't like it\"), \"they do not like it\")\n","    self.assertEqual(expand_contractions(\"he couldn't come\"), \"he could not come\")\n","    self.assertEqual(expand_contractions(\"it won't work\"), \"it will not work\")\n","    self.assertEqual(expand_contractions(\"you're welcome\"), \"you are welcome\")\n","    self.assertEqual(expand_contractions(\"we've finished\"), \"we have finished\")\n","    self.assertEqual(expand_contractions(\"it's a beautiful day\"), \"it is a beautiful day\")\n","    self.assertEqual(expand_contractions(\"they'll be here soon\"), \"they will be here soon\")\n","    self.assertEqual(expand_contractions(\"what's up?\"), \"what is up?\")\n","\n","unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"id":"RG9WFXzr7llZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'] = df['text'].apply(expand_contractions)\n","display(df.head())"],"metadata":{"id":"n2GXMzZs9CXf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["speci√°lis karakterek elt√°vol√≠t√°sa"],"metadata":{"id":"2kkcD9IC56GV"}},{"cell_type":"code","source":["import re\n","\n","def remove_special_characters(text):\n","  \"\"\"Removes special characters from text.\"\"\"\n","  return re.sub(r'[^a-zA-Z0-9\\s]', '', text)"],"metadata":{"id":"wHL1wEIz55m5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","\n","class TestRemoveSpecialCharacters(unittest.TestCase):\n","\n","  def test_remove_special_characters(self):\n","    self.assertEqual(remove_special_characters(\"Hello!@#$ World\"), \"Hello World\")\n","    self.assertEqual(remove_special_characters(\"This string has numbers 123 and symbols!\"), \"This string has numbers 123 and symbols\")\n","    self.assertEqual(remove_special_characters(\"No special characters here.\"), \"No special characters here\")\n","    self.assertEqual(remove_special_characters(\"Another example with $pecial ch@racters\"), \"Another example with pecial chracters\")\n","    self.assertEqual(remove_special_characters(\"\"), \"\")\n","\n","unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"id":"uVU2VeQ46G-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'] = df['text'].apply(remove_special_characters)\n","display(df.head())"],"metadata":{"id":"tQBjg-lB6QhA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tokeniz√°ci√≥"],"metadata":{"id":"RToBM3Z37eFL"}},{"cell_type":"code","source":["from tokenizers.pre_tokenizers import Whitespace\n","import nltk\n","from nltk.tokenize import word_tokenize\n","\n","def pre_tokenize_text(text):\n","  pre_tokenizer = Whitespace()\n","  return pre_tokenizer.pre_tokenize_str(text)"],"metadata":{"id":"a3TW5zqf7dwC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","\n","class TestPreTokenizeText(unittest.TestCase):\n","\n","  def test_pre_tokenize_text(self):\n","    # Adjusted expected output to match the observed behavior (like NLTK's word_tokenize with offsets)\n","    self.assertEqual(pre_tokenize_text(\"Hello! How are you?\"), [('Hello', (0, 5)), ('!', (5, 6)), ('How', (7, 10)), ('are', (11, 14)), ('you', (15, 18)), ('?', (18, 19))])\n","    self.assertEqual(pre_tokenize_text(\"  Leading and trailing spaces  \"), [('Leading', (2, 9)), ('and', (10, 13)), ('trailing', (14, 22)), ('spaces', (23, 29))])\n","    # Adjusted expected output for the case with tabs\n","    self.assertEqual(pre_tokenize_text(\"Multiple\\nlines\\nwith\\t tabs\"), [('Multiple', (0, 8)), ('lines', (9, 14)), ('with', (15, 19)), ('tabs', (21, 25))])\n","    self.assertEqual(pre_tokenize_text(\"SingleSpace\"), [('SingleSpace', (0, 11))])\n","    self.assertEqual(pre_tokenize_text(\"\"), [])\n","\n","# Use TestLoader to load tests from the test case\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestPreTokenizeText)\n","runner = unittest.TextTestRunner()\n","runner.run(suite)"],"metadata":{"id":"aWwK0TZ29SLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'] = df['text'].apply(pre_tokenize_text)\n","display(df.head())"],"metadata":{"id":"wovzLQCt-_A0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Removing stopwords"],"metadata":{"id":"baTAwepZAbjG"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords', quiet=True)\n","\n","def remove_stopwords(tokens):\n","  \"\"\"Removes stopwords from a list of tokens.\"\"\"\n","  stop_words = set(stopwords.words('english'))\n","  return [token for token in tokens if token[0] not in stop_words]"],"metadata":{"id":"jBQV2nTwAbXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import unittest\n","\n","class TestRemoveStopwords(unittest.TestCase):\n","\n","  def test_remove_stopwords(self):\n","    # Example 1: Basic case with common stopwords\n","    self.assertEqual(remove_stopwords([('this', (0, 4)), ('is', (5, 7)), ('a', (8, 9)), ('test', (10, 14))]), [('test', (10, 14))])\n","    # Example 2: No stopwords\n","    self.assertEqual(remove_stopwords([('hello', (0, 5)), ('world', (6, 11))]), [('hello', (0, 5)), ('world', (6, 11))])\n","    # Example 3: Sentence with various stopwords\n","    self.assertEqual(remove_stopwords([('it', (0, 2)), ('is', (3, 5)), ('a', (6, 7)), ('beautiful', (8, 17)), ('day', (18, 21)), ('and', (22, 25)), ('i', (26, 27)), ('am', (28, 30)), ('happy', (31, 36))]), [('beautiful', (8, 17)), ('day', (18, 21)), ('happy', (31, 36))])\n","    # Example 4: Empty list\n","    self.assertEqual(remove_stopwords([]), [])\n","    # Example 5: List with only stopwords\n","    self.assertEqual(remove_stopwords([('to', (0, 2)), ('be', (3, 5)), ('or', (6, 8)), ('not', (9, 12)), ('to', (13, 15)), ('be', (16, 18))]), [])\n","\n","unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"id":"8wEfSTc9AbUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a11bd7ec"},"source":["df['text'] = df['text'].apply(remove_stopwords)\n","display(df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Splitting data**\n","\n","What this tells you:\n","\n","Well-balanced dataset: Your classes are almost perfectly balanced (nearly 50/50), which is ideal. This means your model won't be biased toward predicting one class over the other."],"metadata":{"id":"GMuD1DGOA7pu"}},{"cell_type":"code","source":["# Train and test set\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and temporary sets (80% train, 20% temp)\n","train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Split the temporary set into validation and test sets (50% validation, 50% test)\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n","\n","# Now you have train_df, val_df, and test_df\n","print(f\"Train set size: {len(train_df)}\")\n","print(f\"Validation set size: {len(val_df)}\")\n","print(f\"Test set size: {len(test_df)}\")"],"metadata":{"id":"8tPpZMR-A7bj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Plot distribution for train_df\n","plt.figure(figsize=(8, 6))\n","sns.countplot(x='label', data=train_df)\n","plt.title('Distribution of Labels in Train Dataset')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.show()\n","\n","# Plot distribution for val_df\n","plt.figure(figsize=(8, 6))\n","sns.countplot(x='label', data=val_df)\n","plt.title('Distribution of Labels in Validation Dataset')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.show()\n","\n","# Plot distribution for test_df\n","plt.figure(figsize=(8, 6))\n","sns.countplot(x='label', data=test_df)\n","plt.title('Distribution of Labels in Test Dataset')\n","plt.xlabel('Label')\n","plt.ylabel('Count')\n","plt.show()"],"metadata":{"id":"qFA-K8fwC-cy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Modelling\n","\n"],"metadata":{"id":"fmHgQD2pFJ8M"}},{"cell_type":"markdown","source":["vektor alap√∫ modellek"],"metadata":{"id":"0GUHVg4s9Z44"}},{"cell_type":"markdown","source":["Count Vectorizer"],"metadata":{"id":"zFSStOlK9eZX"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Define X_train, X_test, y_train, y_test from the split dataframes\n","X_train = train_df['text']\n","X_test = test_df['text']\n","y_train = train_df['label']\n","y_test = test_df['label']\n","\n","# Convert list of tuples to strings for CountVectorizer\n","X_train_str = [' '.join([token[0] for token in doc]) for doc in X_train]\n","X_test_str = [' '.join([token[0] for token in doc]) for doc in X_test]\n","\n","# Initialize the CountVectorizer\n","vectorizer = CountVectorizer(max_features=1000)\n","\n","# Fit and transform the training data\n","X_train_cv = vectorizer.fit_transform(X_train_str).toarray()\n","\n","# Transform the validation and test data using the same vectorizer\n","X_test_cv = vectorizer.transform(X_test_str).toarray()\n","\n","print(\"CountVectorizer features shape (training):\", X_train_cv.shape)\n","print(\"CountVectorizer features shape (testing):\", X_test_cv.shape)"],"metadata":{"id":"qIISsVOaA7Zh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Initialize PCA and reduce to 2 components\n","pca = PCA(n_components=2)\n","X_train_cv_pca = pca.fit_transform(X_train_cv)\n","\n","# Map string labels to numerical values for plotting\n","label_map = {'not_spam': 0, 'spam': 1}\n","y_train_numeric = y_train.map(label_map)\n","\n","# Create a scatter plot of the 2D PCA results, colored by numerical labels\n","plt.figure(figsize=(10, 8))\n","scatter = plt.scatter(X_train_cv_pca[:, 0], X_train_cv_pca[:, 1], c=y_train_numeric, cmap='viridis', alpha=0.5)\n","\n","# Add a legend to show the mapping of colors to labels\n","# Create custom legend handles\n","handles = [plt.Line2D([], [], marker='o', color=scatter.cmap(scatter.norm(value)), linestyle='None') for value in label_map.values()]\n","labels = label_map.keys()\n","plt.legend(handles, labels, title=\"Labels\")\n","\n","\n","plt.title('2D PCA of CountVectorizer Features, Colored by Label')\n","plt.xlabel('Principal Component 1')\n","plt.ylabel('Principal Component 2')\n","plt.colorbar(scatter, label='Label') # Add a color bar for clarity\n","plt.show()"],"metadata":{"id":"jIpQqD4QA7XM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TF-IDF"],"metadata":{"id":"cw_KZVod_OIU"}},{"cell_type":"code","source":["# TFIDF\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Convert list of tuples to strings for TfidfVectorizer\n","X_train_str = [' '.join([token[0] for token in doc]) for doc in X_train]\n","X_test_str = [' '.join([token[0] for token in doc]) for doc in X_test]\n","\n","# Initialize the TF-IDF vectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n","\n","# Fit and transform the training data\n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_str)\n","\n","# Transform the validation and test data using the same vectorizer\n","X_test_tfidf = tfidf_vectorizer.transform(X_test_str)\n","\n","print(\"TF-IDF features shape (training):\", X_train_tfidf.shape)\n","print(\"TF-IDF features shape (testing):\", X_test_tfidf.shape)"],"metadata":{"id":"UtZo4Uu9A7Q9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Initialize PCA and reduce to 2 components\n","pca = PCA(n_components=2)\n","X_train_tfidf_pca = pca.fit_transform(X_train_tfidf.toarray()) # Convert sparse matrix to dense for PCA\n","\n","# Map string labels to numerical values for plotting\n","label_map = {'not_spam': 0, 'spam': 1}\n","y_train_numeric = y_train.map(label_map)\n","\n","# Create a scatter plot of the 2D PCA results, colored by numerical labels\n","plt.figure(figsize=(10, 8))\n","scatter = plt.scatter(X_train_tfidf_pca[:, 0], X_train_tfidf_pca[:, 1], c=y_train_numeric, cmap='viridis', alpha=0.5)\n","\n","# Add a legend to show the mapping of colors to labels\n","# Create custom legend handles\n","handles = [plt.Line2D([], [], marker='o', color=scatter.cmap(scatter.norm(value)), linestyle='None') for value in label_map.values()]\n","labels = label_map.keys()\n","plt.legend(handles, labels, title=\"Labels\")\n","\n","\n","plt.title('2D PCA of TF-IDF Features, Colored by Label')\n","plt.xlabel('Principal Component 1')\n","plt.ylabel('Principal Component 2')\n","plt.colorbar(scatter, label='Label') # Add a color bar for clarity\n","plt.show()"],"metadata":{"id":"PVWKXWRFA7Is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Labels\n","\n","train_df_labels = train_df['label'].values\n","val_df_labels = val_df['label'].values\n","test_df_labels = test_df['label'].values\n","\n","print(\"First 5 training labels:\", train_df_labels[:5])\n","print(\"First 5 validation labels:\", val_df_labels[:5])\n","print(\"First 5 test labels:\", test_df_labels[:5])"],"metadata":{"id":"0pfQUq2aA68M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["oszt√°lyoz√≥ modellek"],"metadata":{"id":"r4cuFqqP9iGB"}},{"cell_type":"markdown","source":["Logistic regression"],"metadata":{"id":"X-cFmGJlGWBc"}},{"cell_type":"code","source":["# Model CV\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Initialize the Logistic Regression model\n","model_cv = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n","\n","# Train the model\n","model_cv.fit(X_train_cv, y_train)\n","\n","# Predict on the test data\n","y_pred_cv = model_cv.predict(X_test_cv)\n","\n","# Evaluate the model\n","accuracy_cv = accuracy_score(y_test, y_pred_cv)\n","report_cv = classification_report(y_test, y_pred_cv)\n","\n","print(\"Logistic Regression Model with CountVectorizer Features:\")\n","print(f\"Accuracy: {accuracy_cv:.4f}\")\n","print(\"Classification Report:\")\n","print(report_cv)"],"metadata":{"id":"dnHcVUO4FJyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Generate the confusion matrix for the CountVectorizer model\n","cm_cv = confusion_matrix(y_test, y_pred_cv)\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm_cv, annot=True, fmt='d', cmap='Blues', xticklabels=['not_spam', 'spam'], yticklabels=['not_spam', 'spam'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix for Logistic Regression with CountVectorizer Features')\n","plt.show()"],"metadata":{"id":"9Aj3kZ2yHQdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model TF-IDF\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Initialize the Logistic Regression model\n","model_tfidf = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n","\n","# Train the model\n","model_tfidf.fit(X_train_tfidf, y_train)\n","\n","# Predict on the test data\n","y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n","\n","# Evaluate the model\n","accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n","report_tfidf = classification_report(y_test, y_pred_tfidf)\n","\n","print(\"Logistic Regression Model with TF-IDF Features:\")\n","print(f\"Accuracy: {accuracy_tfidf:.4f}\")\n","print(\"Classification Report:\")\n","print(report_tfidf)"],"metadata":{"id":"Uy_S7pKMFJwM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Generate the confusion matrix for the TF-IDF model\n","cm_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm_tfidf, annot=True, fmt='d', cmap='Blues', xticklabels=['not_spam', 'spam'], yticklabels=['not_spam', 'spam'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix for Logistic Regression with TF-IDF Features')\n","plt.show()"],"metadata":{"id":"yMeZqvZnGuKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the accuracy scores obtained from previous evaluations\n","\n","print(\"Accuracy of Logistic Regression Model with CountVectorizer Features:\", accuracy_cv)\n","print(\"Accuracy of Logistic Regression Model with TF-IDF Features:\", accuracy_tfidf)"],"metadata":{"id":"pKcY0ekRFJmG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Neur√°lis h√°l√≥k  (deep learning)"],"metadata":{"id":"8ojE7-8RImAk"}},{"cell_type":"code","source":["# Model CV\n","\n","import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Convert string labels to numerical labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","\n","# Define the model\n","model_cv = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_cv.shape[1],)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dropout(0.3),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model_cv.compile(optimizer='adam',\n","                 loss='binary_crossentropy',\n","                 metrics=['accuracy'])\n","\n","# Train the model and capture the history\n","history_cv = model_cv.fit(X_train_cv, y_train_encoded, epochs=10, batch_size=50, validation_data=(X_test_cv, y_test_encoded))"],"metadata":{"id":"IytiJ7vKIFvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot training and validation accuracy\n","plt.figure(figsize=(12, 6))\n","plt.plot(history_cv.history['accuracy'], label='Training Accuracy')\n","plt.plot(history_cv.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training and validation loss\n","plt.figure(figsize=(12, 6))\n","plt.plot(history_cv.history['loss'], label='Training Loss')\n","plt.plot(history_cv.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"RPdNVucdIFs5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model TF-IDF\n","\n","import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Convert string labels to numerical labels if they are not already\n","# Assuming y_train and y_test are already defined and contain string labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","\n","# Define the model\n","model_tfidf = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_tfidf.shape[1],)),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dropout(0.3),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","# Compile the model\n","model_tfidf.compile(optimizer='adam',\n","                    loss='binary_crossentropy', # Use binary crossentropy for binary classification\n","                    metrics=['accuracy'])\n","\n","# Train the model\n","history_tfidf = model_tfidf.fit(X_train_tfidf, y_train_encoded, epochs=10, batch_size=50, validation_data=(X_test_tfidf, y_test_encoded))"],"metadata":{"id":"mIzFRw9AIFq2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot training and validation accuracy\n","plt.figure(figsize=(12, 6))\n","plt.plot(history_tfidf.history['accuracy'], label='Training Accuracy')\n","plt.plot(history_tfidf.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy (TF-IDF Model)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training and validation loss\n","plt.figure(figsize=(12, 6))\n","plt.plot(history_tfidf.history['loss'], label='Training Loss')\n","plt.plot(history_tfidf.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss (TF-IDF Model)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"qkWqEsd4IFom"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Naive Bayes  (probabilistic classifier)"],"metadata":{"id":"Ho8ce1ikLHjw"}},{"cell_type":"code","source":["# Naive Bayes Model with CountVectorizer\n","\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Initialize the Multinomial Naive Bayes model\n","# Multinomial Naive Bayes is suitable for text classification with count features\n","model_nb_cv = MultinomialNB()\n","\n","# Train the model\n","model_nb_cv.fit(X_train_cv, y_train)\n","\n","# Predict on the test data\n","y_pred_nb_cv = model_nb_cv.predict(X_test_cv)\n","\n"],"metadata":{"id":"eZb2Vv8NIFmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","accuracy_nb_cv = accuracy_score(y_test, y_pred_nb_cv)\n","report_nb_cv = classification_report(y_test, y_pred_nb_cv)\n","cm_nb_cv = confusion_matrix(y_test, y_pred_nb_cv)\n","\n","print(\"Naive Bayes Model with CountVectorizer Features:\")\n","print(f\"Accuracy: {accuracy_nb_cv:.4f}\")\n","print(\"Classification Report:\")\n","print(report_nb_cv)\n"],"metadata":{"id":"IadxQuwQL-GR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm_nb_cv, annot=True, fmt='d', cmap='Blues', xticklabels=['not_spam', 'spam'], yticklabels=['not_spam', 'spam'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix for Naive Bayes with CountVectorizer Features')\n","plt.show()"],"metadata":{"id":"ExmaxGemMAwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Naive Bayes Model with TF-IDF\n","\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Initialize the Multinomial Naive Bayes model\n","model_nb_tfidf = MultinomialNB()\n","\n","# Train the model\n","model_nb_tfidf.fit(X_train_tfidf, y_train)\n","\n","# Predict on the test data\n","y_pred_nb_tfidf = model_nb_tfidf.predict(X_test_tfidf)\n"],"metadata":{"id":"mQCLokIcIFkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Evaluate the model\n","accuracy_nb_tfidf = accuracy_score(y_test, y_pred_nb_tfidf)\n","report_nb_tfidf = classification_report(y_test, y_pred_nb_tfidf)\n","cm_nb_tfidf = confusion_matrix(y_test, y_pred_nb_tfidf)\n","\n","print(\"Naive Bayes Model with TF-IDF Features:\")\n","print(f\"Accuracy: {accuracy_nb_tfidf:.4f}\")\n","print(\"Classification Report:\")\n","print(report_nb_tfidf)\n"],"metadata":{"id":"dX6uKcZ-MM8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm_nb_tfidf, annot=True, fmt='d', cmap='Blues', xticklabels=['not_spam', 'spam'], yticklabels=['not_spam', 'spam'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix for Naive Bayes with TF-IDF Features')\n","plt.show()"],"metadata":{"id":"Pzr10DoSMPQ4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" COMPLEX BENCHMARKING"],"metadata":{"id":"SQgSNBVZdebJ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Dictionary to store all results\n","benchmark_results = []\n","\n","# 1. Logistic Regression + CountVectorizer\n","print(\"\\n1. Evaluating: Logistic Regression + CountVectorizer\")\n","# y_pred_lr_cv is already available from the Logistic Regression CV model cell\n","benchmark_results.append({\n","    'Model': 'Logistic Regression',\n","    'Features': 'CountVectorizer',\n","    'Accuracy': accuracy_score(y_test, y_pred_cv),\n","    'Precision': precision_score(y_test, y_pred_cv, pos_label='spam'),\n","    'Recall': recall_score(y_test, y_pred_cv, pos_label='spam'),\n","    'F1-Score': f1_score(y_test, y_pred_cv, pos_label='spam')\n","})\n","\n","# 2. Logistic Regression + TF-IDF\n","print(\"2. Evaluating: Logistic Regression + TF-IDF\")\n","# y_pred_lr_tfidf is already available from the Logistic Regression TF-IDF model cell\n","benchmark_results.append({\n","    'Model': 'Logistic Regression',\n","    'Features': 'TF-IDF',\n","    'Accuracy': accuracy_score(y_test, y_pred_tfidf),\n","    'Precision': precision_score(y_test, y_pred_tfidf, pos_label='spam'),\n","    'Recall': recall_score(y_test, y_pred_tfidf, pos_label='spam'),\n","    'F1-Score': f1_score(y_test, y_pred_tfidf, pos_label='spam')\n","})\n","\n","# 3. Naive Bayes + CountVectorizer\n","print(\"3. Evaluating: Naive Bayes + CountVectorizer\")\n","benchmark_results.append({\n","    'Model': 'Naive Bayes',\n","    'Features': 'CountVectorizer',\n","    'Accuracy': accuracy_score(y_test, y_pred_nb_cv),\n","    'Precision': precision_score(y_test, y_pred_nb_cv, pos_label='spam'),\n","    'Recall': recall_score(y_test, y_pred_nb_cv, pos_label='spam'),\n","    'F1-Score': f1_score(y_test, y_pred_nb_cv, pos_label='spam')\n","})\n","\n","# 4. Naive Bayes + TF-IDF\n","print(\"4. Evaluating: Naive Bayes + TF-IDF\")\n","benchmark_results.append({\n","    'Model': 'Naive Bayes',\n","    'Features': 'TF-IDF',\n","    'Accuracy': accuracy_score(y_test, y_pred_nb_tfidf),\n","    'Precision': precision_score(y_test, y_pred_nb_tfidf, pos_label='spam'),\n","    'Recall': recall_score(y_test, y_pred_nb_tfidf, pos_label='spam'),\n","    'F1-Score': f1_score(y_test, y_pred_nb_tfidf, pos_label='spam')\n","})\n","\n","# 5. Neural Network + CountVectorizer\n","print(\"5. Evaluating: Neural Network + CountVectorizer\")\n","y_pred_nn_cv_prob = model_cv.predict(X_test_cv)\n","y_pred_nn_cv_binary = (y_pred_nn_cv_prob > 0.5).astype(int).flatten()\n","y_pred_nn_cv_labels = label_encoder.inverse_transform(y_pred_nn_cv_binary)\n","benchmark_results.append({\n","    'Model': 'Neural Network',\n","    'Features': 'CountVectorizer',\n","    'Accuracy': accuracy_score(y_test, y_pred_nn_cv_labels),\n","    'Precision': precision_score(y_test, y_pred_nn_cv_labels, pos_label='spam'),\n","    'Recall': recall_score(y_test, y_pred_nn_cv_labels, pos_label='spam'),\n","    'F1-Score': f1_score(y_test, y_pred_nn_cv_labels, pos_label='spam')\n","})\n","\n","# 6. Neural Network + TF-IDF\n","print(\"6. Evaluating: Neural Network + TF-IDF\")\n","y_pred_nn_tfidf_prob = model_tfidf.predict(X_test_tfidf)\n","y_pred_nn_tfidf_binary = (y_pred_nn_tfidf_prob > 0.5).astype(int).flatten()\n","y_pred_nn_tfidf_labels = label_encoder.inverse_transform(y_pred_nn_tfidf_binary)\n","benchmark_results.append({\n","    'Model': 'Neural Network',\n","    'Features': 'TF-IDF',\n","    'Accuracy': accuracy_score(y_test, y_pred_nn_tfidf_labels),\n","    'Precision': precision_score(y_test, y_pred_nn_tfidf_labels, pos_label='spam'),\n","    'Recall': recall_score(y_test, y_pred_nn_tfidf_labels, pos_label='spam'),\n","    'F1-Score': f1_score(y_test, y_pred_nn_tfidf_labels, pos_label='spam')\n","})\n","\n","# Create comparison dataframe\n","results_df = pd.DataFrame(benchmark_results)\n","results_df['Model_Feature'] = results_df['Model'] + ' + ' + results_df['Features']\n","\n","print(\"COMPREHENSIVE BENCHMARK RESULTS\")\n","print(results_df.to_string(index=False))\n","\n","# Find best models\n","print(\"BEST PERFORMING MODELS BY METRIC\")\n","\n","best_accuracy = results_df.loc[results_df['Accuracy'].idxmax()]\n","best_precision = results_df.loc[results_df['Precision'].idxmax()]\n","best_recall = results_df.loc[results_df['Recall'].idxmax()]\n","best_f1 = results_df.loc[results_df['F1-Score'].idxmax()]\n","\n","print(f\"\\nüèÜ Best Accuracy:  {best_accuracy['Model_Feature']} ({best_accuracy['Accuracy']:.4f})\")\n","print(f\"üèÜ Best Precision: {best_precision['Model_Feature']} ({best_precision['Precision']:.4f})\")\n","print(f\"üèÜ Best Recall:    {best_recall['Model_Feature']} ({best_recall['Recall']:.4f})\")\n","print(f\"üèÜ Best F1-Score:  {best_f1['Model_Feature']} ({best_f1['F1-Score']:.4f})\")\n"],"metadata":{"id":"fzx_DnZKdeAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualization 1: Bar Chart Comparison\n","print(\"\\nüìä Generating visualizations...\")\n","\n","fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n","fig.suptitle('Model Performance Comparison Across All Metrics', fontsize=16, fontweight='bold')\n","\n","metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n","colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n","\n","for idx, (ax, metric, color) in enumerate(zip(axes.flat, metrics, colors)):\n","    sorted_df = results_df.sort_values(by=metric, ascending=True)\n","    bars = ax.barh(sorted_df['Model_Feature'], sorted_df[metric], color=color, alpha=0.7)\n","\n","    for i, (bar, value) in enumerate(zip(bars, sorted_df[metric])):\n","        ax.text(value + 0.005, i, f'{value:.4f}', va='center', fontweight='bold')\n","\n","    ax.set_xlabel(metric, fontsize=12, fontweight='bold')\n","    ax.set_title(f'{metric} Comparison', fontsize=13, fontweight='bold')\n","    ax.set_xlim([0, 1.05])\n","    ax.grid(axis='x', alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"pI_y63-td4z7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualization 2: Heatmap\n","fig, ax = plt.subplots(figsize=(10, 6))\n","heatmap_data = results_df[['Model_Feature', 'Accuracy', 'Precision', 'Recall', 'F1-Score']].set_index('Model_Feature')\n","\n","sns.heatmap(heatmap_data, annot=True, fmt='.4f', cmap='RdYlGn',\n","            center=0.5, vmin=0, vmax=1,\n","            cbar_kws={'label': 'Score'},\n","            linewidths=1, linecolor='white', ax=ax)\n","\n","ax.set_title('Model Performance Heatmap', fontsize=14, fontweight='bold', pad=20)\n","ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n","ax.set_ylabel('Models', fontsize=12, fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"XNhXSqsmd98Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Statistical Analysis\n","print(\"STATISTICAL ANALYSIS\")\n","\n","print(\"\\nüìà Average Performance by Model Type:\")\n","model_avg = results_df.groupby('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score']].mean()\n","print(model_avg.to_string())\n","\n","print(\"\\nüìà Average Performance by Feature Extraction:\")\n","feature_avg = results_df.groupby('Features')[['Accuracy', 'Precision', 'Recall', 'F1-Score']].mean()\n","print(feature_avg.to_string())"],"metadata":{"id":"gZMxYOIad_5F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Application"],"metadata":{"id":"b7LEC_xLM-9f"}},{"cell_type":"code","source":["import tensorflow as tf\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import MultinomialNB\n","import gradio as gr\n","\n","def preprocess_text_for_prediction(text):\n","    \"\"\"Applies the same preprocessing steps as used for training.\"\"\"\n","    text = to_lowercase(text)\n","    text = remove_whitespace(text)\n","    text = expand_contractions(text)\n","    text = remove_special_characters(text)\n","    tokens = pre_tokenize_text(text)\n","    tokens = remove_stopwords(tokens)\n","    # Convert list of tuples back to string for vectorization\n","    processed_text = ' '.join([token[0] for token in tokens])\n","    return processed_text\n","\n","# Initialize the Logistic Regression model for CountVectorizer\n","model_lr_cv = LogisticRegression(max_iter=1000)\n","model_lr_cv.fit(X_train_cv, y_train)\n","\n","# Initialize the Logistic Regression model for TF-IDF\n","model_lr_tfidf = LogisticRegression(max_iter=1000)\n","model_lr_tfidf.fit(X_train_tfidf, y_train)\n","\n","# Dictionary to store all available models\n","models_dict = {\n","    'CountVectorizer': {\n","        'Logistic Regression': model_lr_cv,\n","        'Naive Bayes': model_nb_cv,\n","        'Neural Network': model_cv\n","    },\n","    'TF-IDF': {\n","        'Logistic Regression': model_lr_tfidf,\n","        'Naive Bayes': model_nb_tfidf,\n","        'Neural Network': model_tfidf\n","    }\n","}\n","\n","# Dictionary to store all available vectorizers\n","vectorizers_dict = {\n","    'CountVectorizer': vectorizer,\n","    'TF-IDF': tfidf_vectorizer\n","}\n","\n","def predict_spam(user_input, vectorizer_choice, model_choice):\n","    \"\"\"\n","    Predicts if the input text is spam or not using the selected vectorizer and model.\n","\n","    Args:\n","        user_input: Text to classify\n","        vectorizer_choice: Which vectorizer to use ('CountVectorizer' or 'TF-IDF')\n","        model_choice: Which model to use ('Logistic Regression', 'Naive Bayes', or 'Neural Network')\n","    \"\"\"\n","    # Preprocess the input text\n","    processed_input = preprocess_text_for_prediction(user_input)\n","\n","    # Get the selected vectorizer\n","    selected_vectorizer = vectorizers_dict[vectorizer_choice]\n","\n","    # Vectorize the processed input\n","    input_vectorized = selected_vectorizer.transform([processed_input])\n","\n","    # Get the selected model\n","    selected_model = models_dict[vectorizer_choice][model_choice]\n","\n","    # Make a prediction based on model type\n","    if isinstance(selected_model, tf.keras.models.Sequential):\n","        # Neural Network prediction\n","        prediction_prob = selected_model.predict(input_vectorized.toarray())[0][0]\n","        prediction_label = 'SPAM' if prediction_prob > 0.5 else 'NOT SPAM'\n","        return prediction_label\n","\n","    elif isinstance(selected_model, (LogisticRegression, MultinomialNB)):\n","        # Logistic Regression or Naive Bayes prediction\n","        prediction_label = selected_model.predict(input_vectorized)[0]\n","        return prediction_label.upper()\n","\n","    else:\n","        return \"ERROR\"\n","\n","# Create the Gradio interface with dropdown selections\n","iface = gr.Interface(\n","    fn=predict_spam,\n","    inputs=[\n","        gr.Textbox(\n","            lines=5,\n","            placeholder=\"Enter text here to check if it's spam...\",\n","            label=\"Input Text\"\n","        ),\n","        gr.Dropdown(\n","            choices=['CountVectorizer', 'TF-IDF'],\n","            value='TF-IDF',\n","            label=\"üîß Select Vectorizer (Feature Extraction Method)\"\n","        ),\n","        gr.Dropdown(\n","            choices=['Logistic Regression', 'Naive Bayes', 'Neural Network'],\n","            value='Logistic Regression',\n","            label=\"Select Classification Model\"\n","        )\n","    ],\n","    outputs=gr.Textbox(label=\"Result\"),\n","    title=\"Advanced Spam Detection System\",\n","    description=\"Enter any text to check if it's spam or not. You can choose different vectorizers and models to compare their performance!\",\n","    theme=gr.themes.Soft()\n",")\n","\n","# Launch the Gradio app\n","iface.launch(debug=True, share=True)"],"metadata":{"id":"kHYReUTIM-QB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4511b79b"},"source":["# **Spam Detekt√°l√°s G√©pi Tanul√°ssal: Projekt √ñsszefoglal√≥**\n","\n","## **1. Modell Funkcionalit√°s**\n","\n","Ez a projekt a spam detekt√°l√°st c√©lozza meg g√©pi tanul√°si modellek seg√≠ts√©g√©vel. A c√©l a bej√∂v≈ë sz√∂veges √ºzenetek \"spam\" vagy \"nem_spam\" (ham) kateg√≥ri√°ba sorol√°sa.\n","\n","### Adat El≈ëfeldolgoz√°si L√©p√©sek:\n","\n","1.  **Kisbet≈±s√≠t√©s**: Az √∂sszes sz√∂veg kisbet≈±sre konvert√°l√°sa a konzisztencia √©s a sz√≥k√©szlet m√©ret√©nek cs√∂kkent√©se √©rdek√©ben.\n","2.  **Sz√≥k√∂z√∂k elt√°vol√≠t√°sa**: A felesleges sz√≥k√∂z√∂k (t√∂bbsz√∂r√∂s sz√≥k√∂z√∂k, tabul√°torok, √∫jsorok) elt√°vol√≠t√°sa.\n","3.  **Kontrakci√≥k kibont√°sa**: A gyakori angol r√∂vid√≠t√©sek (pl. \"i'm\" -> \"i am\") kibont√°sa a szabv√°nyos√≠t√°s √©rdek√©ben.\n","4.  **Speci√°lis karakterek elt√°vol√≠t√°sa**: Az alfanumerikus karaktereken k√≠v√ºli √∂sszes karakter elt√°vol√≠t√°sa.\n","5.  **Tokeniz√°ci√≥**: A sz√∂vegek egyedi szavakra (tokenekre) bont√°sa (`tokenizers.pre_tokenizers.Whitespace()` seg√≠ts√©g√©vel).\n","6.  **Stopword-√∂k elt√°vol√≠t√°sa**: A gyakori, kev√©s inform√°ci√≥t hordoz√≥ szavak (pl. \"the\", \"is\", \"a\") elt√°vol√≠t√°sa az NLTK angol stopword list√°ja alapj√°n.\n","\n","### Jellemz≈ëkinyer√©si M√≥dszerek:\n","\n","1.  **CountVectorizer**: A sz√∂veget egy ritka m√°trixsz√° alak√≠tja, ahol az √©rt√©kek az egyes szavak el≈ëfordul√°si gyakoris√°g√°t jel√∂lik a dokumentumokban. A `max_features=1000` param√©terrel korl√°toztuk a sz√≥k√©szletet a 1000 leggyakoribb sz√≥ra.\n","2.  **TF-IDF (Term Frequency-Inverse Document Frequency)**: S√∫lyozza a szavak el≈ëfordul√°si gyakoris√°g√°t azzal, hogy mennyire ritk√°n vagy gyakran fordulnak el≈ë az eg√©sz korpuszban, √≠gy nagyobb s√∫lyt adva a megk√ºl√∂nb√∂ztet≈ë erej≈± szavaknak. Szint√©n `max_features=1000` param√©terrel haszn√°ltuk.\n","\n","### Alkalmazott Modell Architekt√∫r√°k:\n","\n","1.  **Logisztikus Regresszi√≥**: Egy line√°ris oszt√°lyoz√≥ modell (`sklearn.linear_model.LogisticRegression`), amely line√°ris d√∂nt√©si hat√°rt tanul a kateg√≥ri√°k sz√©tv√°laszt√°s√°ra.\n","2.  **Neuronh√°l√≥ (M√©lytanul√°s)**: Egy egyszer≈± feed-forward neuronh√°l√≥ a `TensorFlow/Keras` seg√≠ts√©g√©vel. K√©t `Dense` r√©tegb≈ël √°llt `ReLU` aktiv√°l√°ssal √©s `Dropout` r√©tegekkel a regulariz√°l√°s √©rdek√©ben, valamint egy v√©gs≈ë `sigmoid` kimeneti r√©teggel bin√°ris oszt√°lyoz√°sra.\n","3.  **Naiv Bayes**: Egy val√≥sz√≠n≈±s√©gi oszt√°lyoz√≥, konkr√©tan a `MultinomialNB` (`sklearn.naive_bayes` k√∂nyvt√°rb√≥l), amely k√ºl√∂n√∂sen alkalmas diszkr√©t jellemz≈ëkkel (mint a sz√≥sz√°mok vagy TF-IDF √©rt√©kek) t√∂rt√©n≈ë oszt√°lyoz√°sra.\n","\n","---\n","\n","## **2. Konkl√∫zi√≥k**\n","\n","A benchmarking eredm√©nyek azt mutatj√°k, hogy minden modell kiv√©telesen j√≥l teljes√≠tett a spam detekt√°l√°si feladatban, nagyon magas pontoss√°got √©rve el.\n","\n","*   **√Åltal√°nos Teljes√≠tm√©ny**: A modellek er≈ës k√©pess√©geket mutattak a spam √©s nem-spam √ºzenetek megk√ºl√∂nb√∂ztet√©s√©ben.\n","*   **Legjobban Teljes√≠t≈ë Modellek Metrik√°k Szerint**:\n","    *   **Pontoss√°g (Accuracy)**: Naiv Bayes + CountVectorizer (0.9976)\n","    *   **Prec√≠zi√≥ (Precision)**: Logisztikus Regresszi√≥ + TF-IDF (0.9976), Neuronh√°l√≥ + CountVectorizer (0.9976)\n","    *   **Recall**: Naiv Bayes + CountVectorizer (1.0000), Naiv Bayes + TF-IDF (1.0000)\n","    *   **F1-Score**: Naiv Bayes + CountVectorizer (0.9976), Naiv Bayes + TF-IDF (0.9976)\n","*   **Jellemz≈ëkinyer≈ë Hat√°sa**: Mind a CountVectorizer, mind a TF-IDF √∂sszehasonl√≠that√≥an magas teljes√≠tm√©nyt ny√∫jtott a k√ºl√∂nb√∂z≈ë modellekn√©l. A Naiv Bayes, k√ºl√∂n√∂sen mindk√©t jellemz≈ëk√©szlettel, t√∂k√©letes recall-t √©rt el a spam detekt√°l√°sban.\n","*   **Modell Robusztuss√°ga**: A magas metrik√°k alapj√°n a modellek robusztusnak t≈±nnek ezen a specifikus adathalmazon.\n","\n","---\n","\n","## **3. Korl√°tok**\n","\n","A magas teljes√≠tm√©ny ellen√©re sz√°mos korl√°tja van a jelenlegi megk√∂zel√≠t√©snek:\n","\n","*   **\"Bag-of-Words\" Felt√©telez√©s**: Mind a CountVectorizer, mind a TF-IDF a sz√∂veget szavak gy≈±jtem√©nyek√©nt kezeli, figyelmen k√≠v√ºl hagyva a sz√≥rendet √©s a nyelvtani szerkezetet. Ez a kontextu√°lis inform√°ci√≥ elveszt√©s√©hez vezethet, ami kritikus lehet a nyelvi √°rnyalatok meg√©rt√©s√©hez.\n","*   **Statikus Sz√≥k√©szlet**: A vektoriz√°l√≥kban haszn√°lt `max_features=1000` korl√°t azt jelenti, hogy minden olyan sz√≥, amely nem szerepel a k√©pz√©si adathalmaz 1000 leggyakoribb szava k√∂z√∂tt, vagy √∫jonnan megjelen≈ë sz√≥, figyelmen k√≠v√ºl marad. Ez korl√°tozza a modell alkalmazkod√°si k√©pess√©g√©t a fejl≈ëd≈ë nyelvi mint√°zatokhoz vagy √∫j spam technik√°khoz.\n","*   **T√∫lilleszt√©s (Overfitting) Potenci√°lja**: B√°r a metrik√°k magasak, a viszonylag kis teszthalmaz (818 minta) √©s a potenci√°lisan egyszer≈± spam mint√°k miatt t√∫lzottan optimista lehet a generaliz√°ci√≥s teljes√≠tm√©ny. A m√©lytanul√°si modellek k√ºl√∂n√∂sen hajlamosak a t√∫lilleszt√©sre kisebb adathalmazokon, megfelel≈ë regulariz√°ci√≥ vagy adatb≈ëv√≠t√©s n√©lk√ºl.\n","*   **Nyelvi F√ºgg≈ës√©g**: Az el≈ëfeldolgoz√°si l√©p√©sek (pl. angol stopword-√∂k, kontrakci√≥k) √©s a modellk√©pz√©s nagym√©rt√©kben az angol nyelvre t√°maszkodnak. Ennek a modellnek m√°s nyelvekre val√≥ alkalmaz√°sa jelent≈ës √∫jratervez√©st √©s √∫jrak√©pz√©st ig√©nyelne.\n","\n","---\n","\n","## **4. J√∂v≈ëbeli Fejleszt√©si Lehet≈ës√©gek**\n","\n","A spam detekt√°l√°si rendszer tov√°bbfejleszt√©se √©rdek√©ben sz√°mos fejlett technika √©s megk√∂zel√≠t√©s vizsg√°lhat√≥:\n","\n","*   **Sz√≥be√°gyaz√°sok (Word Embeddings)**: Word2Vec, GloVe, FastText vagy kontextu√°lis be√°gyaz√°sok (BERT, GPT-2, RoBERTa) bevezet√©se a sz√∂vegbeli szemantikai kapcsolatok √©s kontextus r√∂gz√≠t√©s√©re, t√∫lmutatva a \"bag-of-words\" korl√°tain.\n","*   **Nagyobb √©s Diverzebb Adathalmazok**: Jelent≈ësen nagyobb √©s v√°ltozatosabb spam √©s ham adathalmazokon val√≥ k√©pz√©s jav√≠thatja a generaliz√°ci√≥t, cs√∂kkentheti a t√∫lilleszt√©st, √©s seg√≠thet a modelleknek a finom spam mint√°k detekt√°l√°s√°ban.\n","*   **Dinamikus Sz√≥k√©szlet/Adapt√°ci√≥**: M√≥dszerek vizsg√°lata a modell sz√≥k√©szlet√©nek √©s param√©tereinek folyamatos friss√≠t√©s√©re az √∫j spam taktik√°khoz √©s a fejl≈ëd≈ë nyelvhez val√≥ alkalmazkod√°s √©rdek√©ben.\n","*   **Transfer Learning**: El≈ëre k√©pzett nyelvi modellek haszn√°lata nagyobb sz√∂veges korpuszon, √©s azok finomhangol√°sa a spam detekt√°l√°si feladatra, ami rendk√≠v√ºl hat√©kony lehet kisebb, specifikus adathalmazok eset√©n is.\n","*   **√ârtelmezhet≈ë AI (XAI)**: XAI technik√°k alkalmaz√°sa a m√©lytanul√°si modellek d√∂nt√©seinek meg√©rt√©s√©hez, jav√≠tva a bizalmat √©s lehet≈ëv√© t√©ve a modell jobb hibakeres√©s√©t."]}]}